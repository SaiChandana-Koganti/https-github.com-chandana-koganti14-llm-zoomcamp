# LLM ZoomCamp
# LLM Zoomcamp - Week 1 Experience

## Overview
In the first week of LLM Zoomcamp, I gained valuable insights into Large Language Models (LLMs) and Retrieval-Augmented Generation (RAG). This course, offered by DataTalks.Club and led by Alexey Grigorev, has been instrumental in expanding my skills in AI and machine learning.

## Key Learnings
- Introduction to LLMs and RAG
- Understanding search engines and document indexing
- Performing searches and query handling
- Using OpenAI API for prompt building and invocation
- Exploring alternatives to OpenAI API

## Practical Experience
- Implemented Elasticsearch using Docker
- Practiced indexing and searching techniques
- Applied filtering methods
- Learned to determine prompt length and token count

## Highlights
The most engaging aspect was learning to leverage the OpenAI API to answer queries through prompt engineering. The hands-on experience with Elasticsearch and Docker was particularly enlightening.

## Acknowledgement
Special thanks to Alexey Grigorev and DataTalks.Club for providing this comprehensive and practical course.

## Next Steps
Looking forward to building upon these foundational concepts in the coming weeks and applying them to real-world scenarios.

# LLM Zoomcamp - Week 2 Experience

## Overview
In the second week of LLM Zoomcamp, I delved deeper into open-source Large Language Models (LLMs) and explored various tools for implementing and deploying these models. This week's content has significantly enhanced my understanding of practical LLM applications.

## Key Learnings
- Introduction to different open-source LLMs
- Setting up and using GPU instances
- Exploring models like FLAN T5, Phi-3 Mini, and Mistral 7B
- Running open-source LLMs without GPU using Ollama
- Connecting to OpenAI API
- Setting up a RAG system using Docker Compose
- Introduction to Streamlit for creating user interfaces

## Practical Experience
- Set up a GPU instance using Saturn Cloud
- Implemented and tested various open-source models
- Used Hugging Face to work with Phi-3 Mini and Mistral 7B
- Ran models like Phi-3 and Gemma on local machine and in Docker
- Created a RAG system with Ollama and Elasticsearch
- Developed a UI for the RAG system using Streamlit

## Highlights
The most exciting aspects were gaining free GPU access from Saturn Cloud and creating a functional RAG system with a Streamlit UI. The hands-on experience with various models and tools provided invaluable practical insights.

## Acknowledgement
Special thanks to Alexey Grigorev for the additional Streamlit information and to Saturn Cloud for providing GPU access, which greatly enhanced the learning experience.

## Next Steps
Excited to continue expanding my knowledge in #LLM and #MachineLearning.

